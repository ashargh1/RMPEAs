{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f44b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim, autograd\n",
    "from math import pi\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from bayes_opt import BayesianOptimization\n",
    "import multiprocessing as mp\n",
    "import GPyOpt\n",
    "from sklearn.metrics import r2_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(123456)\n",
    "np.random.seed(123456)\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "\n",
    "class Unit3(nn.Module):\n",
    "    def __init__(self, in_N, out_N,actf):\n",
    "        super(Unit3, self).__init__()\n",
    "        self.in_N = in_N\n",
    "        self.out_N = out_N\n",
    "        self.actf = actf\n",
    "        self.L = nn.Linear(in_N, out_N)\n",
    "\n",
    "    def forward(self, x):\n",
    "        actf=self.actf\n",
    "        x1 = self.L(x)\n",
    "        if actf==0:\n",
    "            x2 = torch.tanh(x1)\n",
    "        elif actf==1:\n",
    "            x2 = torch.sigmoid(x1) \n",
    "        elif actf==2:\n",
    "            x2 = torch.relu(x1)\n",
    "        elif actf==3:\n",
    "            x2 = torch.selu(x1)\n",
    "        elif actf==4:\n",
    "            x2 = F.softmax(x1, dim=1)\n",
    "        return x2\n",
    "    \n",
    "class NN3(nn.Module):\n",
    "    def __init__(self, in_N, width1, depth1,width2, depth2,out_N,bn,dp,dprate,actf):\n",
    "        super(NN3, self).__init__()\n",
    "        self.width1 = width1\n",
    "        self.width2 = width2\n",
    "        self.depth1 = depth1\n",
    "        self.depth2 = depth2\n",
    "        self.bn = bn\n",
    "        self.dp = dp\n",
    "        self.dprate = dprate\n",
    "        self.actf = actf\n",
    "        self.in_N = in_N\n",
    "        self.out_N = out_N\n",
    "        self.stack = nn.ModuleList()\n",
    "        self.stack.append(Unit3(in_N, width1[0],actf))\n",
    "        if bn==1:\n",
    "            self.stack.append(nn.BatchNorm1d(width1[0]))\n",
    "        for i in range(1,depth1):\n",
    "            self.stack.append(Unit3(width1[i-1], width1[i],actf))\n",
    "        \n",
    "        if dp==1:\n",
    "            self.stack.append(nn.Dropout(p=dprate))\n",
    "        if depth2==1:\n",
    "            self.stack.append(Unit3(width1[i], width2[0],1)) \n",
    "        else:\n",
    "            self.stack.append(Unit3(width1[i], width2[0],actf))    \n",
    "            for i in range(1,depth2-1):\n",
    "                self.stack.append(Unit3(width2[i-1], width2[i],actf))\n",
    "            self.stack.append(Unit3(width2[depth2-2], width2[depth2-1],4)) \n",
    "            \n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.stack)):\n",
    "            x = self.stack[i](x)\n",
    "        x = x / x.sum(dim=1, keepdim=True) \n",
    "        return x\n",
    "\n",
    "\n",
    "def nn_cl_bo2(dropout, dropout_rate,normalization,batch_size,layers1, layers2,neurons,learning_rate): \n",
    " \n",
    "    \n",
    "    activation=0\n",
    "    epoch = 50\n",
    "    kfold=10\n",
    "    \n",
    "    layers1 = round(layers1)\n",
    "    layers2 = round(layers2)\n",
    "    neurons = round(neurons)\n",
    "    batch_size = round(batch_size) \n",
    "    activation = round(activation)\n",
    "    bnorm=0\n",
    "    if normalization>0.5:\n",
    "        bnorm=1\n",
    "    dout=0\n",
    "    if dropout>0.5:\n",
    "        dout=1\n",
    "    load=0\n",
    "    PATH=\"checkpoint/model-9.pt\"\n",
    "    if load==1:\n",
    "        checkpoint = torch.load(PATH)\n",
    "        model_h.load_state_dict(checkpoint['model_h_state_dict'])\n",
    "        optimizer2.load_state_dict(checkpoint['optimizer2_state_dict'])\n",
    "    cv = RepeatedKFold(n_splits=kfold, n_repeats=1, random_state=1)  \n",
    "    Tot_acc=np.empty([epoch,3*kfold]) \n",
    "    Tot_acc[:]=np.nan\n",
    "    cv_acc=[]\n",
    "    cv_acc_test=[]\n",
    "    cv_num=0\n",
    "    \n",
    "    post_analysis_train=torch.zeros([kfold,np.shape(xlo)[0],(16)]) \n",
    "    post_analysis_test=torch.zeros([kfold,np.shape(xlo_test)[0],(16)])\n",
    "    \n",
    "    for train_ix, test_ix in cv.split(xlo):\n",
    "        post_analysis_train_1=torch.zeros([0,16])\n",
    "        x_lo_train, x_lo_val = xlo[train_ix], xlo[test_ix]\n",
    "        y_lo_train, y_lo_val = ylo[train_ix], ylo[test_ix]    \n",
    "        L1=[neurons]*layers1\n",
    "        L2=[neurons]*layers2+[8]\n",
    "        model_h = NN3(35,L1,layers1,L2,layers2+1, 8,bnorm,dout,dropout_rate,activation)\n",
    "        model_h.apply(weights_init)\n",
    "        optimizer2 = optim.AdamW([{'params': model_h.parameters()}], lr=learning_rate) \n",
    "        num_batch=np.shape(x_lo_train)[0]//batch_size \n",
    "        loss2_value = 1\n",
    "        earlystop=[]\n",
    "        \n",
    "        for it in range(epoch): \n",
    "            model_h.train()\n",
    "            for batch_i in range(num_batch-1):\n",
    "                loss_fn =torch.nn.MSELoss()\n",
    "                pred_h = model_h(torch.from_numpy(x_lo_train).float()[batch_i*batch_size:(batch_i+1)*batch_size,:])\n",
    "                loss3=loss_fn(pred_h,torch.from_numpy(y_lo_train[batch_i*batch_size:(batch_i+1)*batch_size,:]).float())\n",
    "                \n",
    "                if it==epoch-1:\n",
    "                    Conf_train=torch.cat(((pred_h).float(),torch.from_numpy(y_lo_train[batch_i*batch_size:(batch_i+1)*batch_size,:]).int()),dim=1)\n",
    "                    post_analysis_train_1=torch.cat((post_analysis_train_1,Conf_train),dim=0)\n",
    "\n",
    "                loss2=loss3\n",
    "                loss2_value = loss2.item()\n",
    "                optimizer2.zero_grad()\n",
    "                loss2.backward()\n",
    "                optimizer2.step()\n",
    "            \n",
    "            batch_i=num_batch-1 \n",
    "            pred_h = model_h(torch.from_numpy(x_lo_train).float()[batch_i*batch_size:,:])\n",
    "            loss3=loss_fn(pred_h,torch.from_numpy(y_lo_train[batch_i*batch_size:,:]).float())\n",
    "            \n",
    "            if it==epoch-1:\n",
    "                Conf_train=torch.cat(((pred_h).float(),torch.from_numpy(y_lo_train[batch_i*batch_size:,:]).int()),dim=1)\n",
    "                post_analysis_train_1=torch.cat((post_analysis_train_1,Conf_train),dim=0)\n",
    "                post_analysis_train[cv_num,0:np.shape(post_analysis_train_1)[0],:]=post_analysis_train_1\n",
    "      \n",
    "            loss2=loss3\n",
    "            loss2_value = loss2.item()\n",
    "            optimizer2.zero_grad()\n",
    "            loss2.backward()\n",
    "            optimizer2.step()\n",
    "            \n",
    "            #Train (Final batch)\n",
    "            loss3=loss_fn(pred_h,torch.from_numpy(y_lo_train[batch_i*batch_size:,:]).float())\n",
    "            acc_eval_train=loss3.detach().numpy()\n",
    "            Tot_acc[it,3*cv_num]=acc_eval_train\n",
    "            \n",
    "            #Validate\n",
    "            model_h.eval()\n",
    "            pred_2h_star = model_h(torch.from_numpy(x_lo_val).float())\n",
    "            loss3=loss_fn(pred_2h_star,torch.from_numpy(y_lo_val).float())\n",
    "            acc_eval_val=loss3.detach().numpy()\n",
    "            Tot_acc[it,3*cv_num+1]=acc_eval_val\n",
    "            \n",
    "            #Test\n",
    "            pred_2h_star_test = model_h(torch.from_numpy(xlo_test).float())\n",
    "            loss3=loss_fn(pred_2h_star_test,torch.from_numpy(ylo_test).float())\n",
    "\n",
    "            acc_hi_0_test=(pred_2h_star_test).float()\n",
    "            acc_hi_1_test=torch.from_numpy(ylo_test).float()\n",
    "            \n",
    "            if it==epoch-1:\n",
    "                Conf_test=torch.cat((acc_hi_0_test,acc_hi_1_test),dim=1)\n",
    "                post_analysis_test[cv_num,0:np.shape(Conf_test)[0],:]=Conf_test\n",
    "        \n",
    "\n",
    "            acc_eval_test=loss3.detach().numpy()\n",
    "            Tot_acc[it,3*cv_num+2]=acc_eval_test\n",
    "            \n",
    "            earlystop=np.append(earlystop,acc_eval_val)\n",
    "            if it==epoch-1:\n",
    "                cv_acc=np.append(cv_acc,acc_eval_val) \n",
    "                cv_acc_test=np.append(cv_acc_test,acc_eval_test) \n",
    "\n",
    "        cv_num=cv_num+1\n",
    "        \n",
    "        Output=[dout,dropout_rate,bnorm,batch_size,layers1,layers2,neurons,learning_rate,np.mean(cv_acc),np.mean(cv_acc_test)]\n",
    "        Output=np.reshape(Output,(1,10))\n",
    "        with open(\"BO_Restuls.txt\",\"ab\") as file:\n",
    "            np.savetxt(file,Output,fmt='%.5f %.5f %.5f %.5f %.5f %.5f %.5f %.5f %.5f %.5f') \n",
    "        if cv_num==1:\n",
    "            break\n",
    "    return np.mean(cv_acc)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "xlo=np.load('xlo.npy')\n",
    "ylo=np.load('ylo.npy')\n",
    "xlo_test=np.load('xlo_test.npy')\n",
    "ylo_test=np.load('ylo_test.npy')\n",
    "params_nn2 ={\n",
    "    'batch_size':(32, 1024),\n",
    "    'neurons': (20, 100),\n",
    "    'layers1':(5,10),\n",
    "    'layers2':(0,10),\n",
    "    'normalization':(0,1),\n",
    "    'dropout':(0,1),\n",
    "    'dropout_rate':(0.1,0.6),\n",
    "    'learning_rate':(1e-4, 100e-4)\n",
    "    \n",
    "}\n",
    "nn_bo = BayesianOptimization(nn_cl_bo2, params_nn2, random_state=111)\n",
    "nn_bo.maximize(init_points=40, n_iter=80)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Elapsed time:\", elapsed_time, \"seconds\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
